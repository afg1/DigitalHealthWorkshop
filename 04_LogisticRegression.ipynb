{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f20697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import SimpleITK as sitk\n",
    "\n",
    "import os\n",
    "import time\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    from tqdm import tqdm_notebook as tqdm\n",
    "    haveTQDM = True\n",
    "except:\n",
    "    haveTQDM = False\n",
    "    \n",
    "print(haveTQDM)\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb535629",
   "metadata": {},
   "source": [
    "## Download the data\n",
    "\n",
    "NB: you might not need to do this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619cb55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/ec8y5vb8frdzhfc/HNSCC.zip?dl=0 -O ./HNSCC.zip\n",
    "!unzip -q HNSCC.zip\n",
    "!rm HNSCC.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8e7bab",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "The initial setup can be largely the same as in the other notebooks, lets start by reading the clinical data and processing it in a slightly better way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b875fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the clinical data CSV\n",
    "clinicalDataPath = \"./HNSCC/clinicalData.csv\"\n",
    "\n",
    "clinicalData = pd.read_csv(clinicalDataPath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77be955",
   "metadata": {},
   "source": [
    "In contrast to the last analysis, we are not going to filter patients based on their treatment. Instead, we will include some of their clinical data in the analysis as additional covariates. This will make the analysis a bit trickier, but should mean we have a more robust answer at the end.\n",
    "\n",
    "We will still exlude the 40 fraction patients, as they have an unusual treatment regimen, but otherwise we will use the same BED calculation as before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40cc638",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function should create a voxelwise BED distribution. It makes the assumption that the dose in the plan is delivered in equal fractions\n",
    "## This is obviously not 100% true due to setup uncertainty, motion, etc, but it is an ok assumtion for now\n",
    "\n",
    "## BED = D_t * (1 + D_f/ab)  where:\n",
    "## D_t is the total dose (per voxel)\n",
    "## D_f = D_t/nFrac is the fraction dose per voxel\n",
    "## ab is the alpha/beta ratio\n",
    "\n",
    "def calculateVoxelwiseBED(dose, nFrac, alpha_beta=10.0):\n",
    "    factor = 1.0 / (nFrac*alpha_beta)\n",
    "\n",
    "    BED = dose*(1.0 + dose*factor)\n",
    "\n",
    "    return BED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57da706",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Take all comers, but exclude 40 fraction patients\n",
    "\n",
    "selectedPatients = clinicalData[clinicalData[\"Number of Fractions\"].astype(int) < 40]\n",
    "len(selectedPatients[\"Number of Fractions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761541db",
   "metadata": {},
   "source": [
    "In terms of outcome, we will still look at survival 12 months post radiotherapy, so we can copy the dose loading and outcome specification but from the simpler binary datamining directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2da87e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dosesPath = \"./HNSCC/warpedDoses/\"\n",
    "availableDoses = [\"HNSCC-01-{0}\".format(a.split('.')[0]) for a in os.listdir(dosesPath)]\n",
    "\n",
    "availablePatientsMask = selectedPatients['TCIA code'].isin(availableDoses)\n",
    "probeDose = sitk.GetArrayFromImage(sitk.ReadImage(os.path.join(dosesPath, \"{0:04d}.nii\".format(int(2)))))\n",
    "\n",
    "availablePatients = selectedPatients.loc[availablePatientsMask]\n",
    "len(availablePatients)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "doseArray = np.zeros((len(availablePatients), *probeDose.shape))\n",
    "statusArray = np.zeros((len(availablePatients),))\n",
    "\n",
    "print(doseArray.shape)\n",
    "\n",
    "\n",
    "n = 0\n",
    "for idx, pt in availablePatients.iterrows():\n",
    "    dose_arr = sitk.GetArrayFromImage(sitk.ReadImage(os.path.join(dosesPath, f\"{pt['TCIA code'].split('-')[-1]}.nii\" ) ) )\n",
    "    doseArray[n,...] = calculateVoxelwiseBED(dose_arr, pt[\"Number of Fractions\"], alpha_beta=10.0)\n",
    "    statusArray[n] = int(pt[\"Survival  (months)\"] <= 12) ## survival @ 12 months\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4c8046",
   "metadata": {},
   "source": [
    "## Setting up for logistic regression\n",
    "\n",
    "Logistic regression is a bit different to the other mining we have done so far, because it requires a matrix be built at every voxel, which also contains the clinical variables.\n",
    "\n",
    "Before we can decide what to do about this, we need to figure out what variables we think should be included. We can hypothesis about this for now, but in reality it should be a multi-disciplinary discussion with an experienced clinician\n",
    "\n",
    "For now, lets add\n",
    "\n",
    "- Age at diagnosis ( a continuous variable)\n",
    "- Surgery (a yes/no binary variable)\n",
    "- Sex (Binary Male/Female)\n",
    "- T stage (4 level factor) ???\n",
    "- Dose (continuous ,in Gy, per voxel)\n",
    "\n",
    "In the next cell, we organise the matrix that will contain these variables, and do the necessary transformations so that the logistic regression fitter will understand them\n",
    "\n",
    "\n",
    "Note, after testing, I took the T stage out because it causes some nasty convergence issues (because it is so sparse). This is a problem when working with these types of data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3079b571",
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = availablePatients[\"Age\"].values\n",
    "surgery = (availablePatients[\"Surgery Summary\"] != \"No\").values.astype(np.int32)\n",
    "sex = (availablePatients[\"Sex\"] ==\"Male\").values.astype(np.int32)\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "tstage = encoder.fit_transform(availablePatients['T'].values.reshape((-1,1)), None)\n",
    "clinicalVariableMatrix = np.zeros((len(statusArray), (4))) ## 4 from age, sex, surgery & dose\n",
    "print(ages.shape)\n",
    "\n",
    "## Now put things into the matrix\n",
    "clinicalVariableMatrix[:,0] = ages\n",
    "clinicalVariableMatrix[:,1] = surgery\n",
    "clinicalVariableMatrix[:,2] = sex\n",
    "# clinicalVariableMatrix[:,3:clinicalVariableMatrix.shape[-1]-1] = tstage\n",
    "## Note we leave dose out for now\n",
    "\n",
    "## See what the first row looks like...\n",
    "print(clinicalVariableMatrix[0,:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ecc71e",
   "metadata": {},
   "source": [
    "## Logistic regression loop functions\n",
    "\n",
    "The logistic regression will be done per-voxel, meaning we want to do an independant regression in each one. We therefore need to loop over all the voxels, copy the doses into the last column of our matrix, then compute the logistic regression.\n",
    "\n",
    "The output of the logistic regression will be a single image with a number of channels. The number of channels is determined by the number of variables. In our case, this will be 4. Let's write the loop now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e8b807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_per_voxel(doses, covariates, outcomes, mask=None):\n",
    "    regressor = LogisticRegression(warm_start=True)\n",
    "    flat_dose = doses.reshape((doses.shape[0], -1))\n",
    "    result = np.zeros((flat_dose.shape[1], covariates.shape[-1]))\n",
    "    \n",
    "    if mask is None:\n",
    "        ## loop on voxels\n",
    "        for vox_idx in tqdm(range(flat_dose.shape[-1])):\n",
    "            covariates[:,-1] = flat_dose[:,vox_idx] ## put dose into the regression table\n",
    "            regressor.fit(covariates, outcomes)\n",
    "            result[vox_idx,:] = regressor.coef_\n",
    "        print(flat_dose.shape)\n",
    "    else:\n",
    "        for vox_loc in tqdm(np.argwhere(mask.reshape((-1,)) == 1)):\n",
    "            covariates[:,-1] = flat_dose[:,vox_loc].squeeze() ## put dose into the regression table\n",
    "            regressor.fit(covariates, outcomes)\n",
    "            result[vox_loc,:] = regressor.coef_\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211fb2ae",
   "metadata": {},
   "source": [
    "We now have everything needed to run the per-voxel logistic regression. When I ran this on my laptop, it sounded like it would take off, and didn't really get anywhere!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367df10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = sitk.GetArrayFromImage(sitk.ReadImage(\"./HNSCC/0002_mask.nii\"))#.astype(np.float32)\n",
    "print(np.argwhere(mask == 1))\n",
    "res = logistic_regression_per_voxel(doseArray, clinicalVariableMatrix, statusArray, mask=mask)\n",
    "# print(res.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4004698d",
   "metadata": {},
   "source": [
    "The above cell will take a very long time to run, because it is doing something fairly complicated on a large number of voxels. \n",
    "\n",
    "\n",
    "The next part of the workflow would be to run a permutation test to see if any of the covariates contain a significant region of interest. However, since this already took a long time to run one analysis, running 1000 or more is a prohibitively slow process which we won't do here.\n",
    "\n",
    "Instead, I can show you how to produce the plots which might go into a publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c411b63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(2,2, figsize=(10,10))\n",
    "print(axarr)\n",
    "referenceAnatomy = sitk.GetArrayFromImage(sitk.ReadImage(\"./HNSCC/downsampledCTs/0002.nii\"))[::-1,...]\n",
    "\n",
    "slice_no = 40\n",
    "\n",
    "res = res.reshape((*referenceAnatomy.shape, -1))\n",
    "\n",
    "## Plot the reference CT on all axes\n",
    "for idx, ax in enumerate(axarr.flatten()):\n",
    "    ctImg = ax.imshow(referenceAnatomy[:,slice_no,:], cmap='Greys_r')\n",
    "    channel = ax.imshow(res[::-1,slice_no,:,idx], alpha=0.5)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "fig.tight_layout()\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
